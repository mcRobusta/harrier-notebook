{"cells":[{"cell_type":"code","source":["# Geodesic upsampling finds the maximum XY displacement\n# of an edge from a defined keypoint. From this maximum\n# displacement, we can say the z coordinate is 0. \n# Thus, we can reconstruct the XYZ value of any edge at\n# any time by calculating its XY geodesic to a keypoint\n# and setting the difference between this and the maximum\n#Â XY coordinate as the Z coordinate. Mathematically:\n# z_current**2 = (x_max**2 + y_max**2) - (x_current**2 + y_current**2)\nimport numpy\nimport numba\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport face_alignment\nfrom skimage import color\nimport dlib\nimport os, requests"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["def download_from_url(url, destination):\n  r = requests.get(url, allow_redirects=True)\n  open(destination, 'wb').write(r.content)\n  return destination\n\nlewis_1 = mpimg.imread( download_from_url('https://harriermain.blob.core.windows.net/data/lewis-1.png', 'lewis_1.png') )\nlewis_2 = mpimg.imread( download_from_url('https://harriermain.blob.core.windows.net/data/lewis-2.png', 'lewis_2.png') )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["plt.imshow(lewis_1)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["plt.imshow(lewis_2)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["def segment_faces(image_path): # Extracts unique faces from frames and places them into subfolders.\n    detector = dlib.get_frontal_face_detector()\n    sp = dlib.shape_predictor( download_from_url('https://harriermain.blob.core.windows.net/assets/5mark.dat', '5mark.dat') )\n    facerec = dlib.face_recognition_model_v1( download_from_url('https://harriermain.blob.core.windows.net/assets/facerec.dat', 'facerec.dat') )\n    frame_img = dlib.load_rgb_image(image_path)\n    # Ask the detector to find the bounding boxes of each face. The 1 in the\n    # second argument indicates that we should upsample the image 1 time. This\n    # will make everything bigger and allow us to detect more faces.\n    dets = detector(frame_img, 1)\n    # Now process each face we found.\n    for k, d in enumerate(dets): # For every face detected within the image:\n        # Compute the 128D vector that describes the face in img identified by\n        # shape. If two face vectors have a Euclidean\n        # distance of less than 0.6, they are usually from the same person.\n        croppedFace = frame_img[d.top():d.bottom(), d.left():d.right()]\n    return croppedFace"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["lewis_1c = segment_faces('lewis_1.png')\nplt.imshow(lewis_1c)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["lewis_2c = segment_faces('lewis_2.png')\nplt.imshow(lewis_2c)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["def RGBtoNumpy(img):\n    return color.rgb2gray(numpy.asanyarray(img))\n  \nlewis_1cn = RGBtoNumpy(lewis_1c)\nlewis_2cn = RGBtoNumpy(lewis_2c)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["plt.imshow(lewis_1cn)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["plt.imshow(lewis_2cn)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["@numba.njit\ndef run_kernel(img_numpy, threshold):\n    kernel=numpy.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n    convolved_img = numpy.zeros((len(img_numpy), len(img_numpy[0])), dtype=numpy.float64)\n    kernel_delta = int(numpy.floor(len(kernel)/2))\n    for x in range(kernel_delta, len(img_numpy)-kernel_delta):\n        for y in range(kernel_delta, len(img_numpy[0])-kernel_delta):\n            element = 0\n            for x_k in range(len(kernel)):\n                for y_k in range(len(kernel[0])):\n                    element += img_numpy[(x - kernel_delta) + x_k][(y - kernel_delta) + y_k] * kernel[x_k][y_k]\n            if abs(element) >= threshold:\n                convolved_img[x][y] = 1\n    return convolved_img"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["lewis_grad1 = run_kernel(lewis_1cn, 0.012)\nplt.imshow(lewis_grad1)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["lewis_grad2 = run_kernel(lewis_2cn, 0.012)\nplt.imshow(lewis_grad2)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["@numba.njit\ndef blur_img(img_numpy):\n    kernel=numpy.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n    convolved_img = numpy.zeros((len(img_numpy), len(img_numpy[0])), dtype=numpy.float64)\n    kernel_delta = int(numpy.floor(len(kernel)/2))\n    for x in range(kernel_delta, len(img_numpy)-kernel_delta):\n        for y in range(kernel_delta, len(img_numpy[0])-kernel_delta):\n            element = 0\n            for x_k in range(len(kernel)):\n                for y_k in range(len(kernel[0])):\n                    element += img_numpy[(x - kernel_delta) + x_k][(y - kernel_delta) + y_k] * kernel[x_k][y_k]\n            convolved_img[x][y] = abs(element)\n    return convolved_img\n\nlewis_blur = blur_img(lewis_grad2)\nplt.imshow(lewis_blur)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, flip_input=False)\ndef apply_3D_estimate(image): # , blob_path):\n    # Using FAN, apply 3D estimate to each video frame. Form a \n    # facenet and return each frame result as JSON to CosmosDB.\n    # Include pitch, roll and yaw data given by Face API.\n    #response = requests.post(self.face_api_url, params=self.params, headers=self.headers, json={\"url\": blob_path})\n    landmarks = self.fa.get_landmarks(image)\n    return landmarks_list\n  \nprint(apply_3d_estimate(lewis_1c))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AssertionError</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1029793613186922&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>fa <span class=\"ansi-blue-fg\">=</span> face_alignment<span class=\"ansi-blue-fg\">.</span>FaceAlignment<span class=\"ansi-blue-fg\">(</span>face_alignment<span class=\"ansi-blue-fg\">.</span>LandmarksType<span class=\"ansi-blue-fg\">.</span>_3D<span class=\"ansi-blue-fg\">,</span> flip_input<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">def</span> apply_3D_estimate<span class=\"ansi-blue-fg\">(</span>image<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-red-fg\"># , blob_path):</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>     <span class=\"ansi-red-fg\"># Using FAN, apply 3D estimate to each video frame. Form a</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>     <span class=\"ansi-red-fg\"># facenet and return each frame result as JSON to CosmosDB.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>     <span class=\"ansi-red-fg\"># Include pitch, roll and yaw data given by Face API.</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/face_alignment/api.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, landmarks_type, network_size, device, flip_input, face_detector, verbose)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         face_detector_module = __import__(&#39;face_alignment.detection.&#39; + face_detector,\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>                                           globals(), locals(), [face_detector], 0)\n<span class=\"ansi-green-fg\">---&gt; 66</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>face_detector <span class=\"ansi-blue-fg\">=</span> face_detector_module<span class=\"ansi-blue-fg\">.</span>FaceDetector<span class=\"ansi-blue-fg\">(</span>device<span class=\"ansi-blue-fg\">=</span>device<span class=\"ansi-blue-fg\">,</span> verbose<span class=\"ansi-blue-fg\">=</span>verbose<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>         <span class=\"ansi-red-fg\"># Initialise the face alignemnt networks</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/face_alignment/detection/sfd/sfd_detector.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, device, path_to_detector, verbose)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     43</span>         self<span class=\"ansi-blue-fg\">.</span>face_detector <span class=\"ansi-blue-fg\">=</span> s3fd<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     44</span>         self<span class=\"ansi-blue-fg\">.</span>face_detector<span class=\"ansi-blue-fg\">.</span>load_state_dict<span class=\"ansi-blue-fg\">(</span>torch<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span>path_to_detector<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 45</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>face_detector<span class=\"ansi-blue-fg\">.</span>to<span class=\"ansi-blue-fg\">(</span>device<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     46</span>         self<span class=\"ansi-blue-fg\">.</span>face_detector<span class=\"ansi-blue-fg\">.</span>eval<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     47</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class=\"ansi-cyan-fg\">to</span><span class=\"ansi-blue-fg\">(self, *args, **kwargs)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>             <span class=\"ansi-green-fg\">return</span> t<span class=\"ansi-blue-fg\">.</span>to<span class=\"ansi-blue-fg\">(</span>device<span class=\"ansi-blue-fg\">,</span> dtype <span class=\"ansi-green-fg\">if</span> t<span class=\"ansi-blue-fg\">.</span>is_floating_point<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span> non_blocking<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span> \n<span class=\"ansi-green-fg\">--&gt; 443</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_apply<span class=\"ansi-blue-fg\">(</span>convert<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    444</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    445</span>     <span class=\"ansi-green-fg\">def</span> register_backward_hook<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> hook<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class=\"ansi-cyan-fg\">_apply</span><span class=\"ansi-blue-fg\">(self, fn)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    201</span>     <span class=\"ansi-green-fg\">def</span> _apply<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> fn<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    202</span>         <span class=\"ansi-green-fg\">for</span> module <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>children<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 203</span><span class=\"ansi-red-fg\">             </span>module<span class=\"ansi-blue-fg\">.</span>_apply<span class=\"ansi-blue-fg\">(</span>fn<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    204</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    205</span>         <span class=\"ansi-green-fg\">def</span> compute_should_use_set_data<span class=\"ansi-blue-fg\">(</span>tensor<span class=\"ansi-blue-fg\">,</span> tensor_applied<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class=\"ansi-cyan-fg\">_apply</span><span class=\"ansi-blue-fg\">(self, fn)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    223</span>                 <span class=\"ansi-red-fg\"># `with torch.no_grad():`</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    224</span>                 <span class=\"ansi-green-fg\">with</span> torch<span class=\"ansi-blue-fg\">.</span>no_grad<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 225</span><span class=\"ansi-red-fg\">                     </span>param_applied <span class=\"ansi-blue-fg\">=</span> fn<span class=\"ansi-blue-fg\">(</span>param<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    226</span>                 should_use_set_data <span class=\"ansi-blue-fg\">=</span> compute_should_use_set_data<span class=\"ansi-blue-fg\">(</span>param<span class=\"ansi-blue-fg\">,</span> param_applied<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    227</span>                 <span class=\"ansi-green-fg\">if</span> should_use_set_data<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class=\"ansi-cyan-fg\">convert</span><span class=\"ansi-blue-fg\">(t)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    439</span>             <span class=\"ansi-green-fg\">if</span> convert_to_format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">and</span> t<span class=\"ansi-blue-fg\">.</span>dim<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">4</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    440</span>                 <span class=\"ansi-green-fg\">return</span> t<span class=\"ansi-blue-fg\">.</span>to<span class=\"ansi-blue-fg\">(</span>device<span class=\"ansi-blue-fg\">,</span> dtype <span class=\"ansi-green-fg\">if</span> t<span class=\"ansi-blue-fg\">.</span>is_floating_point<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span> non_blocking<span class=\"ansi-blue-fg\">,</span> memory_format<span class=\"ansi-blue-fg\">=</span>convert_to_format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 441</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> t<span class=\"ansi-blue-fg\">.</span>to<span class=\"ansi-blue-fg\">(</span>device<span class=\"ansi-blue-fg\">,</span> dtype <span class=\"ansi-green-fg\">if</span> t<span class=\"ansi-blue-fg\">.</span>is_floating_point<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">,</span> non_blocking<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    443</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_apply<span class=\"ansi-blue-fg\">(</span>convert<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/torch/cuda/__init__.py</span> in <span class=\"ansi-cyan-fg\">_lazy_init</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    147</span>             raise RuntimeError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    148</span>                 &#34;Cannot re-initialize CUDA in forked subprocess. &#34; + msg)\n<span class=\"ansi-green-fg\">--&gt; 149</span><span class=\"ansi-red-fg\">         </span>_check_driver<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    150</span>         <span class=\"ansi-green-fg\">if</span> _cudart <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    151</span>             raise AssertionError(\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/torch/cuda/__init__.py</span> in <span class=\"ansi-cyan-fg\">_check_driver</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     45</span> <span class=\"ansi-green-fg\">def</span> _check_driver<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     46</span>     <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> hasattr<span class=\"ansi-blue-fg\">(</span>torch<span class=\"ansi-blue-fg\">.</span>_C<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;_cuda_isDriverSufficient&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 47</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> AssertionError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Torch not compiled with CUDA enabled&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     48</span>     <span class=\"ansi-green-fg\">if</span> <span class=\"ansi-green-fg\">not</span> torch<span class=\"ansi-blue-fg\">.</span>_C<span class=\"ansi-blue-fg\">.</span>_cuda_isDriverSufficient<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     49</span>         <span class=\"ansi-green-fg\">if</span> torch<span class=\"ansi-blue-fg\">.</span>_C<span class=\"ansi-blue-fg\">.</span>_cuda_getDriverVersion<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">AssertionError</span>: Torch not compiled with CUDA enabled</div>"]}}],"execution_count":15},{"cell_type":"code","source":["nosetip_array = nosetip_array # 1D list of nosetips for each frame; nosetip_array[frame_number]\nsuper_edge_list = edge_list # 2D list of frame edges; super_edge_list[frame_number][edge_number]\nmatched_edges = [] # 2D list of edges that are found throughout multiple frames; matched_edges[edge_id][frame_number]\n\ndef normalise_edge(edge_list):\n    # Rescale every edge to length 1. This allows \n    # for uniform comparison.\n    edge_geodesic = 0\n    for count in range(1, len(edge_list)):\n        edge_geodesic += (edge_list[count-1])**2 + (edge_list[count])**2\n    edge_geodesic **= 0.5\n    for x in range(len(edge_list)):\n        edge_list[x] /= edge_geodesic\n    return edge_list"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["def track_edges():\n# Blur edges and compile onto single frame.\n# Calculate overlap of edges in adjacent frames,\n# as a normalised square mean of overlap pixels.\n# If blurs overlap in adjacent frames is sufficient,\n# (>0.9), then edges are the same and can be\n# geodesically upsampled.\nfor frame in range(1, len(self.super_edge_list)):\n    edge_list1 = self.super_edge_list[frame-1]\n    edge_list2 = self.super_edge_list[frame]\n    edge_list1 = self.normalise_edge(edge_list1)\n    edge_list2 = self.normalise_edge(edge_list2)\n    for edge_number, edge1 in enumerate(edge_list1):\n        similarity_max = 0\n        matched_edge = None\n        for edge2 in edge_list2:\n            counter = 0\n            square_sum = 0\n            # num_vertices is the number of vertices that both\n            # edges can be compared by. Additional vertices show \n            # the edges are of increasingly different shape: for \n            # every unshared vertex between edges, the similarity\n            # measure is reduced.\n            if len(edge1) < len(edge2):\n                num_vertices = len(edge1)\n                num_vertices_delta = len(edge2) - num_vertices\n            else:\n                num_vertices = len(edge2)\n                num_vertices_delta = len(edge1) - num_vertices\n            for y in range(num_vertices):\n                # Compute Euclidian distance between points.\n                # Find similarity through inverse square law of relation.\n                mid_x = edge1[y][0] - edge2[y][0]\n                mid_x **= 2\n                mid_y = edge1[y][1] - edge2[y][1]\n                mid_y **= 2\n                square_sum += 1/(mix_x + mid_y + 1)\n                counter += 1\n            for z in range(num_vertices_delta):\n                # Similarity is taxed for every vertex that \n                # cannot be matched.\n                counter += 1\n            similarity = square_sum / counter\n            if similarity > similarity_max and similarity > 0.9:\n                similarity_max = similarity\n                matched_edge = edge2\n        if matched_edge == None:\n            # 'frame' is a frame reference used later to find the appropriate nosetip.\n            self.matched_edges[len(self.matched_edges)+1].append((edge1, frame))\n        else:\n            self.matched_edges[self.matched_edges.index(edge1)].append((matched_edge, frame))\n        self.super_edge_list[frame][edge_number] = [self.super_edge_list[frame][edge_number], self.matched_edges.index(edge1)]"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["def compute_max_geodesics(self):\n        for edge_list in self.matched_edges: # For every edge identified throughout multiple frames:\n            max_geodesic = 0 # Let's start here.\n            for edge in edge_list: # For every variation of the identified edge:\n                edge_array = edge[0] # Remember the edge is saved as [(x,y), frame_id]\n                nosetip = self.nosetip_array[edge[1]] # Find the nosetip according to frame id.\n                geodesic = (edge_array[0] - nosetip[0])**2 \n                geodesic += (edge_array[1] - nosetip[1])**2\n                if geodesic > max_geodesic:\n                    max_geodesic = geodesic\n            max_geodesic **= 0.5\n            edge_list.append(max_geodesic)\n            max_geodesic_list.append(max_geodesic) # This is the largest XY distance of this edge to nosetip.\n        return max_geodesic_list"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["def reconstruct_3D_edges(self, index, fa_3D_depth):\n    # Search through matched_edges and match max_geodesics\n    # to values in frame via frame index. This is for creating a dataset only:\n    # don't use this for 3D reconstruction of previously unprocessed frames.\n    edge_3D = [[]]\n    for iterator, edge in enumerate(self.super_edge_list[index]):\n        edge_data = edge[0]\n        edge_reference = edge[1]\n        max_geodesic = self.matched_edges[edge_reference][-1]\n        nosetip = self.nosetip_array[index]\n        for edge_point in edge_data:\n            depth = (nosetip[0] - edge_point[0])**2\n            depth += (nosetip[1] - edge_point[1])**2\n            depth **= 0.5\n            depth += fa_3D_depth\n            edge_3D[iterator].append([edge_point[0], edge_point[1], depth])\n    return edge_3D"],"metadata":{},"outputs":[],"execution_count":19}],"metadata":{"name":"harrier-edges","notebookId":1753465227312613},"nbformat":4,"nbformat_minor":0}
